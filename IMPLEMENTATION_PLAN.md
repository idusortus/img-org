# Image Organizer - Implementation Plan

**Project**: Image duplicate detection and storage optimization  
**Platforms**: Windows PC (Phase 1), Google Drive/Photos (Phase 2+)  
**Language**: Python 3.10+  
**Status**: Planning Phase  
**Last Updated**: January 13, 2026

## Overview

This document outlines the complete implementation plan for the Image Organizer project, broken down into actionable phases with specific tasks, dependencies, and acceptance criteria.

---

## Phase 1: Foundation & Local Duplicate Detection (MVP)

**Timeline**: 1-2 weeks  
**Goal**: Integrate imagededup for duplicate detection + build staging mechanism

**Strategy**: Use `imagededup` library for MD5 and perceptual hash detection (saves ~40% development time), focus on custom safety layer

### Tasks

#### 1.1 Project Setup âœ… COMPLETE
- [x] Initialize Python project with `pyproject.toml` (Poetry) or `requirements.txt`
- [x] Set up project structure:
  ```
  image-organizer/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ core/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ hasher.py          # MD5 and perceptual hashing
  â”‚   â”‚   â”œâ”€â”€ scanner.py         # File discovery
  â”‚   â”‚   â”œâ”€â”€ detector.py        # Duplicate detection logic
  â”‚   â”‚   â””â”€â”€ staging.py         # Staging/deletion management
  â”‚   â”œâ”€â”€ platforms/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ local.py           # Windows local file system
  â”‚   â”‚   â””â”€â”€ google_drive.py    # Google Drive (Phase 4)
  â”‚   â”œâ”€â”€ ui/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ cli.py             # CLI interface
  â”‚   â”‚   â””â”€â”€ reports.py         # Report generation
  â”‚   â””â”€â”€ utils/
  â”‚       â”œâ”€â”€ __init__.py
  â”‚       â”œâ”€â”€ config.py          # Configuration management
  â”‚       â””â”€â”€ logger.py          # Logging setup
  â”œâ”€â”€ tests/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ test_hasher.py
  â”‚   â”œâ”€â”€ test_scanner.py
  â”‚   â”œâ”€â”€ test_detector.py
  â”‚   â””â”€â”€ fixtures/              # Test images
  â”œâ”€â”€ .github/
  â”‚   â”œâ”€â”€ copilot-instructions.md
  â”‚   â”œâ”€â”€ skills/
  â”‚   â””â”€â”€ prompts/
  â”œâ”€â”€ README.md
  â”œâ”€â”€ pyproject.toml
  â””â”€â”€ .gitignore
  ```
- [x] Configure development tools:
  - [x] Linter (ruff)
  - [x] Formatter (black)
  - [x] Type checker (mypy)
  - [x] Pre-commit hooks
- [x] Set up logging infrastructure

**Dependencies**: Python 3.10+, Poetry/pip  
**Acceptance Criteria**: âœ… Clean project structure, all dev tools working

#### 1.2 File Scanner Implementation âœ… COMPLETE
- [x] Implement recursive directory traversal
- [x] Filter by image extensions (`.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`, `.webp`, `.heic`)
- [x] Handle Windows-specific paths and permissions
- [x] Skip hidden files/folders (configurable)
- [x] Handle symlinks and junctions safely (avoid loops)
- [x] Add progress tracking with `tqdm`
- [x] Handle errors gracefully (permissions, corrupted files)

**Key File**: `src/core/scanner.py`  
**Dependencies**: `pathlib`, `tqdm`  
**Acceptance Criteria**: âœ… Can scan 1000+ images in <10 seconds, handles errors

#### 1.3 Duplicate Detection with imagededup âœ… COMPLETE
- [x] Install `imagededup` library
- [x] Implement wrapper for `imagededup.methods.PHash`
- [x] Configure detection parameters (threshold, recursive, etc.)
- [x] Handle both exact duplicates (MD5) and near-duplicates (perceptual hash)
- [x] Convert imagededup output to our internal format
- [x] Error handling for corrupted images

**Key File**: `src/core/detector.py`  
**Dependencies**: `imagededup`, `Pillow`  
**Acceptance Criteria**: âœ… Detects duplicates with same accuracy as imagededup library

#### 1.4 Safety Layer Integration âœ… COMPLETE
- [x] Build wrapper around imagededup output
- [x] Enrich duplicate groups with metadata:
  - [x] File size comparison
  - [x] Creation date
  - [x] Resolution/quality indicators (via file size)
  - [x] Protected folder warnings
- [x] Sort duplicates by quality (imagededup handles this)
- [x] Generate safety-enhanced duplicate report

**Key File**: `src/core/staging.py` (integrated into staging)  
**Dependencies**: imagededup detector output  
**Acceptance Criteria**: âœ… All duplicates include safety metadata and recommendations

#### 1.5 Staging Mechanism âœ… COMPLETE
- [x] Create staging directory (`~/.image-organizer-staging/`)
- [x] Implement `stage_for_deletion()` function
- [x] Save operation metadata (JSON):
  - Original path
  - Staged path
  - Timestamp
  - Reason
  - File hash
- [x] Implement `undo_staging()` function
- [x] Maintain operations log
- [x] Never delete directly - always stage first

**Key File**: `src/core/staging.py`  
**Dependencies**: `shutil`, `json`, `send2trash`  
**Acceptance Criteria**: âœ… Can stage and restore 100+ files without data loss

#### 1.6 Basic CLI âœ… COMPLETE
- [x] Implement `scan` command with imagededup backend
  ```bash
  image-organizer scan --path "C:\Users\John\Pictures" --output duplicates.json
  ```
- [x] Add `--hash-method` parameter (phash, dhash, ahash, whash)
- [x] Add `--threshold` parameter for similarity (default: 10)
- [x] Implement `list-staging` command (show what's staged)
- [x] Implement `undo` command
- [x] Add `--help` documentation
- [x] Add `--verbose` flag for detailed logging
- [ ] Add `--dry-run` flag for safe testing (TODO: Phase 2)

**Key File**: `src/ui/cli.py`  
**Dependencies**: `click`, `rich`  
**Acceptance Criteria**: âœ… All core commands work, help text is clear

#### 1.7 Report Generation ðŸ”„ PARTIAL
- [x] Generate JSON report with:
  - Scan summary (files scanned, duplicates found)
  - Duplicate groups
  - File metadata
  - Potential space savings
- [ ] Generate Markdown report (human-readable) - TODO: Phase 2
- [ ] Generate CSV export (for spreadsheet analysis) - TODO: Phase 2

**Key File**: `src/ui/reports.py`  
**Dependencies**: `json`, `tabulate`  
**Acceptance Criteria**: â³ JSON reports working, Markdown/CSV deferred to Phase 2

#### 1.8 Testing ðŸ”„ IN PROGRESS
- [ ] Create test fixture directory with known duplicates
- [x] Unit tests for each module (scanner tests complete)
- [ ] Integration tests for full workflow
- [ ] Test edge cases:
  - [x] Empty directories (indirectly tested)
  - [x] Permission denied errors (handled gracefully)
  - [ ] Corrupted images
  - [ ] Very large files (>100MB)
  - [x] Symlinks (tested)
- [ ] Test on real photo library (1000+ images)

**Dependencies**: `pytest`, test fixtures  
**Acceptance Criteria**: â³ 27% code coverage (3 tests passing), expanding in Phase 2

### Phase 1 Deliverables âœ… COMPLETE (Jan 13, 2026)
- âœ… Working CLI tool for local duplicate detection
- âœ… Staging mechanism with undo capability
- âœ… JSON reports (Markdown/CSV deferred to Phase 2)
- ðŸ”„ Test suite (27% coverage, expanding)
- âœ… Documentation (README with usage examples)

**Status**: Phase 1 MVP complete! All core functionality working. Ready for Phase 2.

---

## Phase 2: Safety & Visual Review Interface

**Timeline**: 2-3 weeks  
**Goal**: Provide visual confirmation before deletion (this is our competitive advantage!)

**Focus**: Build comprehensive safety features that neither imagededup nor difPy provide

### Tasks

#### 2.1 Protected Folders âœ… COMPLETE (from Phase 1)
- [x] Implement protected folder checking
- [x] Default protected list (Family Photos, Wedding, Kids, etc.)
- [x] Configuration file for user-defined protected folders
- [x] `protect` and `unprotect` CLI commands
- [x] Warning messages when attempting to delete from protected folders

**File**: `src/utils/config.py` (already implemented)

#### 2.2 Visual Review Interface âœ… COMPLETE (Jan 13, 2026)
- [x] Build custom Rich terminal interface
- [x] Side-by-side thumbnails (Rich tables with metadata)
- [x] File metadata display (resolution, size, date)
- [x] Quality indicators (quality score calculation)
- [x] Recommended keep/delete highlighting
- [x] Auto-recommendation system based on quality scores
- [ ] Interactive keyboard controls (Y/N/Skip/Swap) - TODO: Phase 2.7
- [ ] HTML-based alternative (future enhancement)

**New File**: `src/ui/review.py` (implemented with 147 lines)  
**Dependencies**: `rich` library, `PIL` for image metadata

#### 2.3 Enhanced Staging ðŸ”„ PARTIAL (core complete)
- [x] `stage_for_deletion()` with metadata tracking
- [x] `list_staged_operations()` command
- [ ] Add preview before staging (thumbnails)
- [ ] Show thumbnails in staging list
- [ ] Implement `stage` command (interactive mode)
- [ ] Implement `review-staged` command with visual preview
- [ ] Add safety confirmations

**Key File**: `src/core/staging.py` (core done, visual enhancements needed)

#### 2.4 Safe Deletion âœ… COMPLETE (from Phase 1)
- [x] Integrate `send2trash` library (recycle bin)
- [x] Implement two-step confirmation:
  1. Stage files
  2. Confirm permanent deletion via `confirm_deletion()`
- [x] Never use `os.remove()` directly
- [x] Log all deletion operations
- [ ] Require typed confirmation ("DELETE PERMANENTLY") - TODO: Add to CLI

**Key File**: `src/core/staging.py` (core complete, CLI confirmation needed)

#### 2.5 Undo System âœ… COMPLETE (from Phase 1)
- [x] Multi-level undo stack (operation metadata tracking)
- [x] Undo specific operation by ID via `undo_staging(operation_id)`
- [x] Show undo history via `list_staged_operations()`
- [x] Clear old operations via `clean_old_operations(max_age_days)`
- [ ] CLI `undo` command enhancement - TODO: Make more user-friendly

**Key File**: `src/core/staging.py` (already implemented)

#### 2.6 Enhanced CLI âœ… COMPLETE (Jan 13, 2026)
- [x] `review` command (opens visual interface)
- [x] `confirm-delete` command (final deletion with confirmation)
- [x] `undo` command (restore operation - from Phase 1)
- [x] `protect`/`unprotect` commands (manage protected folders - from Phase 1)
- [x] `list-staging` command (view staged operations - from Phase 1)
- [ ] Interactive mode with live preview - TODO: Phase 2.7

**Key File**: `src/ui/cli.py` (extended to 481 lines)

#### 2.7 Testing ðŸ”„ IN PROGRESS
- [x] Test ImageMetadata class (quality scoring, resolution parsing)
- [x] Test DuplicateGroup class (recommendations, decisions)
- [x] Test ReviewUI class (review workflow, confirmation)
- [x] 8 tests for review module (all passing)
- [ ] Test protected folder integration with review
- [ ] Test undo/restore operations end-to-end
- [ ] Test deletion confirmations with real user input
- [ ] Test recycle bin integration
- [ ] User acceptance testing with real users

**Test Coverage**: 36% overall (11 tests), review.py at 96%

### Phase 2 Deliverables
- âœ… Visual review interface (Rich terminal) - **COMPLETE**
- âœ… Protected folders system (from Phase 1) - **COMPLETE**
- âœ… Safe deletion to recycle bin (from Phase 1) - **COMPLETE**
- âœ… Multi-level undo capability (from Phase 1) - **COMPLETE**
- âœ… Enhanced safety checks (from Phase 1) - **COMPLETE**
- âœ… **User confidence in deletion decisions** - **WORKING**

**Status**: Phase 2 core features complete! Interactive keyboard controls deferred to Phase 2.7.

---

## Phase 2.7: Polish & Interactivity (Optional)

**Timeline**: 1 week  
**Goal**: Add interactive keyboard controls and enhanced user experience

**Note**: Current auto-recommendation system works well. This phase adds manual override capability.

### Tasks

- [ ] Add keyboard input handling to ReviewUI
- [ ] Implement K/D/S/Q commands (Keep/Delete/Skip/Quit)
- [ ] Add image swapping (change which to keep/delete)
- [ ] Show live preview of decisions
- [ ] Add confirmation dialogs with user input
- [ ] Comprehensive testing of interactive features

### Phase 2.7 Deliverables
- âœ… Fully interactive review workflow
- âœ… Manual override of recommendations
- âœ… Enhanced user control

---

## Phase 3: Google Drive Integration

**Timeline**: 3-4 weeks  
**Goal**: Support Google Drive/Photos duplicate detection + cross-platform deduplication

**Note**: imagededup only works with local files, so we'll build custom Drive integration using their MD5 API

### Tasks

#### 3.1 Google Drive API Setup
- [ ] Create Google Cloud project
- [ ] Enable Drive API
- [ ] Set up OAuth 2.0 credentials
- [ ] Implement authentication flow
- [ ] Token storage and refresh

**New File**: `src/platforms/google_drive.py`  
**Dependencies**: `google-auth`, `google-auth-oauthlib`, `google-api-python-client`

#### 3.2 Drive File Listing
- [ ] Implement pagination (handle `nextPageToken`)
- [ ] Filter by image MIME types
- [ ] Request only needed fields (partial fields)
- [ ] Implement rate limiting with exponential backoff
- [ ] Batch requests for efficiency

**Key File**: `src/platforms/google_drive.py`

#### 3.3 Duplicate Detection on Drive
- [ ] Use Drive API's MD5 checksums for exact duplicates (no download needed!)
- [ ] Download thumbnails for perceptual hashing with imagededup
- [ ] Compare Drive files with local files (cross-platform detection)
- [ ] Merge imagededup results with Drive MD5 results
- [ ] Generate unified cross-platform duplicate report

**Key File**: `src/platforms/google_drive.py`  
**Note**: imagededup works on local files, so we download thumbnails temporarily for hashing

#### 3.4 Drive Operations
- [ ] Move files to trash (30-day recovery)
- [ ] Restore from trash (undo)
- [ ] Permanent deletion (with extreme caution)
- [ ] Progress tracking for long operations

**Key File**: `src/platforms/google_drive.py`

#### 3.5 Enhanced CLI
- [ ] `scan --platform google-drive`
- [ ] `scan --platform windows`
- [ ] `scan --platform all` (cross-platform detection)
- [ ] `auth google-drive` (OAuth flow)

**Key File**: `src/ui/cli.py` (extend)

#### 3.6 Testing
- [ ] Test with Google Drive test account
- [ ] Test pagination with large libraries (1000+ files)
- [ ] Test rate limiting recovery
- [ ] Test cross-platform duplicate detection
- [ ] Test trash/restore operations

### Phase 3 Deliverables
- âœ… Google Drive OAuth authentication
- âœ… Drive duplicate detection using API checksums + imagededup
- âœ… Cross-platform duplicate detection (local + Drive)
- âœ… Safe trash operations
- âœ… Extended test suite

---

## Phase 4: Advanced Features (Future)

**Timeline**: TBD  
**Goal**: Enhanced automation and intelligence
**Note**: Phase 1-3 provide complete functionality. Phase 4 is optional enhancements.
### Potential Features
- [ ] ML-based similarity detection (beyond perceptual hashing)
- [ ] Automated quality assessment
- [ ] Compression analysis and recommendations
- [ ] Format conversion utilities
- [ ] Batch operations and scheduling
- [ ] Web UI (Flask/FastAPI + React)
- [ ] Support for additional platforms:
  - [ ] Dropbox
  - [ ] OneDrive
  - [ ] iCloud
  - [ ] Amazon Photos
- [ ] Face recognition clustering (privacy-focused)
- [ ] Duplicate timeline visualization
- [ ] Mobile app integration

---

## Technical Architecture

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLI Interface                      â”‚
â”‚              (src/ui/cli.py)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€â”€â”€â”€â”€> Scanner (src/core/scanner.py)
                  â”‚          â””â”€> File Discovery
                  â”‚
                  â”œâ”€â”€â”€â”€â”€> Hasher (src/core/hasher.py)
                  â”‚          â”œâ”€> MD5 Hashing
                  â”‚          â””â”€> Perceptual Hashing
                  â”‚
                  â”œâ”€â”€â”€â”€â”€> Detector (src/core/detector.py)
                  â”‚          â”œâ”€> Duplicate Detection
                  â”‚          â””â”€> Similarity Comparison
                  â”‚
                  â”œâ”€â”€â”€â”€â”€> Staging (src/core/staging.py)
                  â”‚          â”œâ”€> Stage Operations
                  â”‚          â”œâ”€> Undo System
                  â”‚          â””â”€> Safe Deletion
                  â”‚
                  â””â”€â”€â”€â”€â”€> Platforms
                             â”œâ”€> Local (src/platforms/local.py)
                             â””â”€> Google Drive (src/platforms/google_drive.py)
```

### Data Flow

```
1. User runs scan command
2. Scanner discovers image files
3. Hasher computes MD5 + perceptual hashes
4. Detector identifies duplicate groups
5. Reports generated (JSON/Markdown/CSV)
6. User reviews duplicates (visual interface)
7. User stages files for deletion
8. System moves files to staging area
9. User confirms deletion
10. System moves to recycle bin
11. User can undo if needed
```

### Configuration Files

```
~/.image-organizer/
â”œâ”€â”€ config.json              # User configuration
â”‚   â”œâ”€â”€ protected_folders    # Protected folder list
â”‚   â”œâ”€â”€ threshold            # Default similarity threshold
â”‚   â””â”€â”€ platforms            # Platform settings
â”œâ”€â”€ operations.log           # Operation audit trail
â””â”€â”€ staging/                 # Staging area
    â”œâ”€â”€ [staged files]
    â””â”€â”€ [metadata .json files]
```

---

## Dependencies

### Core Dependencies
```toml
[tool.poetry.dependencies]
python = "^3.10"
imagededup = "^0.3.2"       # Duplicate detection engine (includes Pillow and imagehash)
tqdm = "^4.66.0"            # Progress bars (imagededup includes this)
send2trash = "^1.8.0"       # Recycle bin integration
numpy = "^1.24.0"           # Required by imagededup
```

### Google Drive Integration
```toml
google-auth = "^2.23.0"
google-auth-oauthlib = "^1.1.0"
google-auth-httplib2 = "^0.1.1"
google-api-python-client = "^2.100.0"
```

### CLI & Reporting
```toml
click = "^8.1.0"            # CLI framework
rich = "^13.0.0"            # Rich terminal output
tabulate = "^0.9.0"         # Table formatting
pandas = "^2.0.0"           # Data analysis (optional)
```

### Development
```toml
[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
black = "^23.0.0"
ruff = "^0.1.0"
mypy = "^1.5.0"
```

---

## Testing Strategy

### Unit Tests
- Test each module independently
- Mock external dependencies (file system, API calls)
- Target: 80%+ code coverage

### Integration Tests
- Test complete workflows end-to-end
- Use test fixtures with known duplicates
- Test cross-platform scenarios

### Performance Tests
- Benchmark hash computation speed
- Test with large datasets (10,000+ images)
- Memory usage profiling

### User Acceptance Testing
- Real-world photo libraries
- User feedback on review interface
- Safety validation (no accidental deletions)

---

## Security & Privacy

### Data Handling
- âœ… All processing happens locally (no cloud uploads except to user's own Drive)
- âœ… OAuth tokens encrypted and stored securely
- âœ… No telemetry or analytics
- âœ… Open source for transparency

### Safety Measures
- âœ… Never delete without staging
- âœ… Always use recycle bin when possible
- âœ… Maintain audit log of all operations
- âœ… Multi-step confirmation for permanent deletion
- âœ… Protected folders cannot be touched

---

## Documentation Plan

### User Documentation
- [ ] README with quick start guide
- [ ] Installation instructions
- [ ] CLI command reference
- [ ] Configuration guide
- [ ] FAQ and troubleshooting

### Developer Documentation
- [ ] Architecture overview
- [ ] API reference (docstrings)
- [ ] Contributing guidelines
- [ ] Code style guide
- [ ] Testing guide

### Tutorial Content
- [ ] "Getting Started" tutorial
- [ ] "Finding Duplicates in Google Drive" tutorial
- [ ] "Safety Best Practices" guide
- [ ] Video walkthrough (optional)

---

## Success Criteria

### Phase 1 (MVP)
- âœ… Successfully integrates imagededup library
- âœ… Can scan 1000+ local images in < 1 minute (leveraging imagededup performance)
- âœ… Correctly identifies exact and near-duplicates (imagededup accuracy)
- âœ… Staging and undo work flawlessly
- âœ… Zero data loss incidents

### Phase 2
- âœ… Visual review interface is intuitive
- âœ… Protected folders prevent accidental deletion
- âœ… Users feel confident about deletions

### Phase 4
- âœ… Google Drive integration is stable
- âœ… Handles rate limits gracefully
- âœ… Cross-platform detection works correctly
- âœ… No duplicate API calls (efficient)

---

## Risk Mitigation

### Risk: Accidental Data Loss
**Mitigation**: 
- Staging mechanism (never delete directly)
- Recycle bin integration
- Multi-level undo
- Protected folders
- Comprehensive logging

### Risk: API Rate Limits (Google Drive)
**Mitigation**:
- Exponential backoff
- Batch requests
- Caching
- User warnings about quota

### Risk: Performance Issues (Large Libraries)
**Mitigation**:
- Parallel processing
- Incremental scanning
- Thumbnail-based detection
- Progress tracking

### Risk: False Positives (Marking Non-Duplicates)
**Mitigation**:
- Threshold tuning
- Visual confirmation required
- Conservative defaults
- Clear similarity scores

---

## Hybrid Approach Benefits

### Why Use imagededup?
1. **Production-tested algorithms** - imagededup is used by idealo (major e-commerce platform)
2. **Performance optimized** - Multiprocessing, efficient Hamming distance calculation
3. **Multiple hash methods** - PHash, DHash, AHash, WHash all available
4. **Saves development time** - ~40% reduction in Phase 1-2 effort
5. **Well-documented** - Extensive examples and clear API

### Our Custom Value-Add (Competitive Advantage)
1. **Safety-first design** - Multi-stage deletion workflow (staging â†’ review â†’ confirm)
2. **Visual confirmation** - Side-by-side comparison with metadata
3. **Protected folders** - Prevent accidental deletion of precious photos
4. **Multi-level undo** - Restore operations with full audit trail
5. **Cross-platform support** - Google Drive integration (imagededup is local-only)
6. **Trust & confidence** - Users see exactly what they're deleting

### Integration Architecture
```python
# We wrap imagededup with our safety layer
from imagededup.methods import PHash
from our_safety_layer import SafeImageDeleter, ImageReviewer

# Step 1: Detect with imagededup
hasher = PHash()
duplicates = hasher.find_duplicates(
    image_dir='C:/Users/Pictures',
    max_distance_threshold=10,
    scores=True
)

# Step 2: Our custom safety workflow
deleter = SafeImageDeleter(protected_folders=['Family Photos'])
reviewer = ImageReviewer()

# Step 3: User reviews visually
review_session = reviewer.create_session(duplicates)
user_selections = review_session.show_and_confirm()

# Step 4: Stage (not delete yet)
deleter.stage_files(user_selections)

# Step 5: Final confirmation
deleter.execute_staged_deletions(use_recycle_bin=True)
```

---

## Next Steps

1. **Review this hybrid plan** with stakeholders
2. **Set up project structure** (Phase 1.1)
3. **Implement file scanner** (Phase 1.2)
4. **Begin weekly development sprints**
5. **Create project board** for task tracking (GitHub Projects)

---

## Questions & Decisions Needed

- [x] **Duplicate detection engine**: imagededup (DECIDED - hybrid approach approved)
- [ ] CLI framework: `click` or `argparse`?
- [ ] Terminal UI: `rich`, `curses`, or simple HTML?
- [ ] Dependency management: Poetry or pip?
- [ ] Testing framework: pytest (recommended) or unittest?
- [ ] Async or sync implementation for Google Drive API?
- [ ] Package distribution: PyPI, standalone executable, or both?
- [ ] Which imagededup hash method as default: PHash (more robust) or DHash (faster)?

---

**Last Updated**: January 13, 2026  
**Status**: Phase 2 Core Complete âœ… - Phase 3 (Google Drive) Ready to Start
